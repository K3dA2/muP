{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle\n",
    "! mkdir ~/.kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download scribbless/another-anime-face-dataset\n",
    "! unzip another-anime-face-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/K3dA2/VQ-VAE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/VQ-VAE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from muP.model import VAE,VAEConfig\n",
    "from utils import get_data_loader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_loss(mu,l_sigma):\n",
    "    kl_loss = -0.5 * torch.sum(1 + l_sigma - mu**2 - torch.exp(l_sigma))\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, config, num_epochs=20):\n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    kl_weight = 0.0001\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model.learning_rate)\n",
    "    \n",
    "    # Move model to the configured device\n",
    "    model.to(config.device)\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False) as epoch_pbar:\n",
    "            for data in train_loader:\n",
    "                inputs, _ = data\n",
    "                inputs = inputs.to(config.device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                mu, l_sigma, outputs = model(inputs)\n",
    "\n",
    "                kl = kl_loss(mu, l_sigma)\n",
    "                # Compute loss\n",
    "                mse = criterion(outputs, inputs)\n",
    "                loss = mse + (kl * kl_weight)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Accumulate loss\n",
    "                running_loss += loss.item()\n",
    "                epoch_pbar.set_postfix({'loss': running_loss / (epoch_pbar.n + 1)})\n",
    "                epoch_pbar.update(1)\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss}')\n",
    "    \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, config):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(config.device)\n",
    "            mu, l_sigma, outputs = model(inputs)\n",
    "            # Display the original and reconstructed images\n",
    "            model.reconstruct(inputs)\n",
    "            break  # Only visualize the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ayanfe/Documents/Datasets/Waifus/Train'\n",
    "val_path = '/Users/ayanfe/Documents/Datasets/Waifus/Val'\n",
    "\n",
    "train_loader = get_data_loader(path, batch_size=64, num_samples=40_000)\n",
    "test_loader = get_data_loader(val_path, batch_size=64, num_samples=10_000)\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different configurations\n",
    "learning_rates = [0.0005, 3e-4 ,0.0001]\n",
    "base_channel_sizes = [32, 64, 128]\n",
    "\n",
    "results = {}\n",
    "\n",
    "total_iterations = len(learning_rates) * len(base_channel_sizes)\n",
    "with tqdm(total=total_iterations, desc=\"Training models\") as pbar:\n",
    "    for lr in learning_rates:\n",
    "        for base_channels in base_channel_sizes:\n",
    "            print(f\"Training with learning rate: {lr} and base channels: {base_channels}\")\n",
    "            \n",
    "            config = VAEConfig(input_channels=3, z_dim=8, base_channels=base_channels, device=device, learning_rate=lr)\n",
    "            model = VAE(config)\n",
    "            \n",
    "            loss_history = train_model(model, train_loader, config, num_epochs=10)\n",
    "            results[(lr, base_channels)] = loss_history\n",
    "            test_model(model, test_loader, config)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "plt.figure(figsize=(12, 8))\n",
    "for (lr, base_channels), loss_history in results.items():\n",
    "    plt.plot(loss_history, label=f'LR: {lr}, Base Channels: {base_channels}')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss for Different Learning Rates and Base Channel Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
